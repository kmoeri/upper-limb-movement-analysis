{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Extract Kinematic Parameters From Movement Data",
   "id": "fe235cd74e5da434"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 1) Imports",
   "id": "210a6d0502ca277b"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# libraries\n",
    "import os\n",
    "import toml\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import signal\n",
    "from scipy.signal import butter, sosfiltfilt\n",
    "\n",
    "# modules\n",
    "import motion_processing\n",
    "from src import utils\n",
    "import visualizations as visu"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 2) Config",
   "id": "4b6d5048096824fc"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# read config data\n",
    "with open('config.toml', 'r') as f:\n",
    "    config = toml.load(f)\n",
    "\n",
    "# load relevant paths\n",
    "preprocessed_data_path: str = config['batch_preprocessing']['prepro_out_path']\n",
    "param_extract_out_path: str = config['parameter_extraction']['param_extract_out_path']\n",
    "\n",
    "# global variables\n",
    "FRAMERATE = config['camera_params']['framerate']\n"
   ],
   "id": "cbb5264ac7cb3051",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 3) Load Movement Data to Dictionary",
   "id": "e9960a53661c3288"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# read preprocessed files form path\n",
    "hands_data_file_lst: list = [os.path.join(preprocessed_data_path, x) for x in sorted(os.listdir(preprocessed_data_path))\n",
    "                             if x.endswith('hands_processed.csv') and not x.startswith('.')]\n",
    "# sort\n",
    "hands_data_file_lst = sorted(hands_data_file_lst)\n",
    "\n",
    "# organize by exercise\n",
    "hand_exercise_dict: dict = utils.group_motion_files_by_exercise(hands_data_file_lst)\n",
    "\n",
    "print('Number of participants represented per exercise: ')\n",
    "for key in hand_exercise_dict.keys():\n",
    "    print(f'Exercise {key}: {len(hand_exercise_dict[key])} participants')"
   ],
   "id": "7127dcbae2f2182c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 4) Exercise-Specific Parameter Extraction",
   "id": "14ab42c0dc595776"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\n",
    "\n",
    "def extract_landmarks_of_focus(movement_fpath: str, landmark_lst: list) -> list:\n",
    "    \"\"\"\n",
    "    Renames basic landmark names with appropriate index (1: left, 2: right)\n",
    "\n",
    "    Args:\n",
    "        movement_fpath (str): movement file path.\n",
    "        landmark_lst (list): list of landmark names.\n",
    "\n",
    "    Returns:\n",
    "        new_landmark_lst (list): modified list of landmark names. Extends landmark names with index of focused side.\n",
    "    \"\"\"\n",
    "    single_digit_landmark_lst: list = ['wrist', 'elbow', 'shoulder']\n",
    "\n",
    "    task_df = pd.read_csv(movement_fpath)\n",
    "\n",
    "    # infer the side focused in the given trial\n",
    "    focus_side: str = utils.infer_focus_side(task_df, model_type='Hand')\n",
    "\n",
    "    landmark_model_id: str = ''\n",
    "    if focus_side == 'Left':\n",
    "        landmark_model_id = '1'\n",
    "    elif focus_side == 'Right':\n",
    "        landmark_model_id = '2'\n",
    "    else:\n",
    "        print(f'Error: The focused hand side {focus_side} is invalid.')\n",
    "\n",
    "    # create the list of landmarks for the focused side\n",
    "    new_landmark_lst: list = [(x[:-1] + landmark_model_id + x[-1]) if x not in single_digit_landmark_lst\n",
    "                              else (x[:] + landmark_model_id) for x in landmark_lst]\n",
    "\n",
    "    return new_landmark_lst\n",
    "\n",
    "\n",
    "def extract_irregular_movements_parameters(raw_signal: np.ndarray,\n",
    "                                           framerate: float = FRAMERATE,\n",
    "                                           plot_results: bool = False,\n",
    "                                           detection_config: dict = None) -> dict:\n",
    "    \"\"\"\n",
    "    Extracts movement parameters using a 2-Pass adaptive strategy:\n",
    "    1) Scout: gets Median amplitude and median Period of the time series as estimators.\n",
    "    2) Harvester: uses adaptive peak detection initialized with scout estimators to find valid peaks/valleys\n",
    "\n",
    "    Args:\n",
    "        raw_signal (np.ndarray): The raw signal (time series).\n",
    "        framerate (float): Sampling rate in Hz.\n",
    "        plot_results (bool, optional): Whether to plot the results. Defaults to False.\n",
    "        detection_config (dict, optional): A dictionary containing detection parameters. Defaults to None.\n",
    "\n",
    "    Returns:\n",
    "        features (dict): Dictionary with extracted movement features\n",
    "    \"\"\"\n",
    "\n",
    "    # configuration setup\n",
    "    config_params = {'min_segment_length': 0.05,\n",
    "                     'min_peak_amp_diff': 0.15,\n",
    "                     'min_valley_amp_diff': 0.15,\n",
    "                     'max_peak_amp_diff': None,\n",
    "                     'max_valley_amp_diff': None,\n",
    "                     'prominence_factor': 0.35,\n",
    "                     'distance_factor': 0.35}\n",
    "\n",
    "    # update dictionary with passed config (if available)\n",
    "    if detection_config:\n",
    "        config_params.update(detection_config)\n",
    "\n",
    "    features = {\n",
    "        'repetition_freq': 0.0, 'num_repetitions': 0.0,\n",
    "        'period_mean': 0.0, 'period_std': 0.0, 'period_min': 0.0, 'period_max': 0.0,\n",
    "        'amplitude_mean': 0.0, 'amplitude_std': 0.0, 'amplitude_min': 0.0, 'amplitude_max': 0.0,\n",
    "        'velocity_pos_mean': 0.0, 'velocity_pos_std': 0.0,\n",
    "        'velocity_neg_mean': 0.0, 'velocity_neg_std': 0.0,\n",
    "        'extraction_status': 'failed',\n",
    "        'valid_peaks_idx': [],\n",
    "        'valid_valleys_idx': []\n",
    "    }\n",
    "\n",
    "    n_samples = len(raw_signal)\n",
    "    if n_samples < framerate:\n",
    "        print(f'Error: Trial skipped. Samples ({n_samples}) < Framerate ({framerate})')\n",
    "        features['extraction_status'] = 'failed'\n",
    "        return features\n",
    "\n",
    "    # 1) preprocessing\n",
    "    def robust_detrend(signal_data: np.ndarray, framerate: float = framerate, cutoff: float = 0.3) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Removes complex, non-linear trends using a Zero-Phase High-Pass Filter.\n",
    "        Better than linear detrending for signals with wandering baselines.\n",
    "\n",
    "        Args:\n",
    "            signal_data: The raw signal.\n",
    "            framerate: Sampling rate in Hz.\n",
    "            cutoff: Frequency below which to remove data (Hz). Defaults to 0.3 Hz (removes trends slower than 3.3s).\n",
    "\n",
    "        Returns:\n",
    "            np.ndarray: Detrended signal of same shape as the input signal.\n",
    "        \"\"\"\n",
    "        # safety fallback: signal too short for the filter (< 3x filter length) -> fall back to linear detrend\n",
    "        if len(signal_data) < 3 * (framerate / cutoff):\n",
    "            return signal.detrend(signal_data, type='linear')\n",
    "\n",
    "        # 2nd order Butterworth High-Pass Filter with numerically more stable 'sos' output\n",
    "        sos = butter(2, cutoff, btype='highpass', fs=framerate, output='sos')\n",
    "\n",
    "        # apply filter forward and backward (zero phase distortion)\n",
    "        # centers the signal around 0\n",
    "        return sosfiltfilt(sos, signal_data)\n",
    "\n",
    "    # detrend the signal\n",
    "    try:\n",
    "        detrended_signal = robust_detrend(raw_signal, framerate, cutoff=0.3)\n",
    "    except NameError:\n",
    "        detrended_signal = signal.detrend(raw_signal, type='linear')\n",
    "\n",
    "    # =========================================================================\n",
    "    # PASS 1: THE SCOUT (Zero-Crossing)\n",
    "    # Goal: Get robust Median Amplitude and Median Period from high-confidence anchors.\n",
    "    # =========================================================================\n",
    "\n",
    "    signs = np.sign(detrended_signal)\n",
    "    signs[signs == 0] = 1\n",
    "    crossings = np.where(np.diff(signs))[0]\n",
    "\n",
    "    scout_peaks = []\n",
    "    scout_valleys = []\n",
    "\n",
    "    if len(crossings) >= 2:\n",
    "        for i in range(len(crossings) - 1):\n",
    "            seg_start, seg_end = crossings[i], crossings[i+1]\n",
    "            if (seg_end - seg_start) < (framerate * config_params['min_segment_length']):\n",
    "                continue\n",
    "\n",
    "            segment = detrended_signal[seg_start:seg_end]\n",
    "            if np.mean(segment) > 0:\n",
    "                scout_peaks.append({'idx': seg_start + np.argmax(segment), 'amp': np.max(segment)})\n",
    "            else:\n",
    "                scout_valleys.append({'idx': seg_start + np.argmin(segment), 'amp': abs(np.min(segment))})\n",
    "\n",
    "    # failsafe: if scout misses everything, tuning fails.\n",
    "    if len(scout_peaks) < 2 or len(scout_valleys) < 1:\n",
    "        features['extraction_status'] = 'failed_scout_pass'\n",
    "        return features\n",
    "\n",
    "    # extract statistics from scout\n",
    "    median_peak_amp = np.median([p['amp'] for p in scout_peaks])\n",
    "    median_valley_amp = np.median([v['amp'] for v in scout_valleys])\n",
    "\n",
    "    scout_peak_indices = sorted([p['idx'] for p in scout_peaks])\n",
    "    median_period_samples = np.median(np.diff(scout_peak_indices))\n",
    "\n",
    "    # =========================================================================\n",
    "    # PASS 2: THE HARVESTER (Prominence-Based)\n",
    "    # Goal: Find ALL valid peaks/valleys, including those below zero.\n",
    "    # =========================================================================\n",
    "\n",
    "    # dynamic tuning\n",
    "    prominence_threshold_peak = config_params['prominence_factor'] * median_peak_amp\n",
    "    prominence_threshold_valley = config_params['prominence_factor'] * median_valley_amp\n",
    "    distance_threshold = int(config_params['distance_factor'] * median_period_samples)\n",
    "    distance_threshold = max(distance_threshold, 1)\n",
    "\n",
    "    # 1) Find peaks using prominence and distance threshold\n",
    "    peak_idxs, _ = signal.find_peaks(detrended_signal,\n",
    "                                     prominence=prominence_threshold_peak,\n",
    "                                     distance=distance_threshold)\n",
    "\n",
    "    # 2) Find valleys\n",
    "    valley_idxs, _ = signal.find_peaks(-detrended_signal,\n",
    "                                       prominence=prominence_threshold_valley,\n",
    "                                       distance=distance_threshold)\n",
    "\n",
    "    potential_peaks = [{'idx': i, 'amp': detrended_signal[i], 'type': 'peak'} for i in peak_idxs]\n",
    "    potential_valleys = [{'idx': i, 'amp': abs(detrended_signal[i]), 'type': 'valley'} for i in valley_idxs]\n",
    "\n",
    "    # Filter pass 2 candidates\n",
    "    filtered_peaks = []\n",
    "    for p in potential_peaks:\n",
    "\n",
    "        # apply ceiling if the peak is positive and large (reject large artifacts)\n",
    "        if config_params['max_peak_amp_diff'] and p['amp'] > 0:\n",
    "             if p['amp'] > (config_params['max_peak_amp_diff'] * median_peak_amp):\n",
    "                 continue\n",
    "\n",
    "        filtered_peaks.append(p)\n",
    "\n",
    "    filtered_valleys = []\n",
    "    for v in potential_valleys:\n",
    "\n",
    "        # ceiling check\n",
    "        if config_params['max_valley_amp_diff'] and v['amp'] > (config_params['max_valley_amp_diff'] * median_valley_amp):\n",
    "            continue\n",
    "\n",
    "        filtered_valleys.append(v)\n",
    "\n",
    "    # Enforce proper alternation of peaks and valleys\n",
    "    def _clean_alternation(peaks, valleys):\n",
    "        all_events = sorted(peaks + valleys, key=lambda x: x['idx'])\n",
    "        if not all_events: return [], []\n",
    "\n",
    "        clean_events = [all_events[0]]\n",
    "        for current in all_events[1:]:\n",
    "            last = clean_events[-1]\n",
    "\n",
    "            if current['type'] == last['type']:\n",
    "                # Keep the maximum: peak -> highest; valleys -> lowest\n",
    "                if current['amp'] > last['amp']:\n",
    "                    clean_events.pop()\n",
    "                    clean_events.append(current)\n",
    "            else:\n",
    "                clean_events.append(current)\n",
    "\n",
    "        return [e for e in clean_events if e['type'] == 'peak'], [e for e in clean_events if e['type'] == 'valley']\n",
    "\n",
    "    valid_peaks, valid_valleys = _clean_alternation(filtered_peaks, filtered_valleys)\n",
    "\n",
    "    features['valid_peaks_idx'] = [p['idx'] for p in valid_peaks]\n",
    "    features['valid_valleys_idx'] = [v['idx'] for v in valid_valleys]\n",
    "\n",
    "    if len(valid_peaks) < 2:\n",
    "         features['extraction_status'] = 'failed_insufficient_reps'\n",
    "         return features\n",
    "\n",
    "    # =========================================================================\n",
    "    # METRICS CALCULATION\n",
    "    # =========================================================================\n",
    "\n",
    "    # Period\n",
    "    peak_indices = [p['idx'] for p in valid_peaks]\n",
    "    period_diffs = np.diff(peak_indices) / framerate\n",
    "    features.update(utils.get_descriptive_stats(np.array(period_diffs), 'period'))\n",
    "\n",
    "    # Reps & Freq\n",
    "    avg_period = features['period_mean']\n",
    "    if avg_period > 0:\n",
    "        features['repetition_freq'] = round(1.0 / avg_period, 2)\n",
    "        valid_duration = (peak_indices[-1] - peak_indices[0]) / framerate\n",
    "        features['num_repetitions'] = round(valid_duration * features['repetition_freq'] + 1, 1)\n",
    "\n",
    "    # Amplitude (P-P)\n",
    "    amplitudes = []\n",
    "    for p in valid_peaks:\n",
    "        p_idx = p['idx']\n",
    "        next_valleys = [v for v in valid_valleys if v['idx'] > p_idx]\n",
    "        if next_valleys:\n",
    "            v = next_valleys[0]\n",
    "            if (v['idx'] - p_idx) / framerate < (1.5 * avg_period):\n",
    "\n",
    "                # raw signal values\n",
    "                raw_p = detrended_signal[p['idx']]\n",
    "                raw_v = detrended_signal[v['idx']]\n",
    "                amplitudes.append(raw_p - raw_v)\n",
    "\n",
    "    if amplitudes:\n",
    "        features.update(utils.get_descriptive_stats(np.array(amplitudes), 'amplitude'))\n",
    "\n",
    "    # Velocity\n",
    "    velocity_curve = np.gradient(detrended_signal, 1/framerate)\n",
    "    rise_vels, fall_vels = [], []\n",
    "    all_events = sorted(valid_peaks + valid_valleys, key=lambda x: x['idx'])\n",
    "\n",
    "    for i in range(len(all_events) - 1):\n",
    "        curr, next_evt = all_events[i], all_events[i+1]\n",
    "        start, end = curr['idx'], next_evt['idx']\n",
    "\n",
    "        start = max(0, start)\n",
    "        end = min(len(velocity_curve), end)\n",
    "\n",
    "        if start < end:\n",
    "            vel_seg = velocity_curve[start:end]\n",
    "            if len(vel_seg) > 0:\n",
    "                if next_evt['type'] == 'peak':\n",
    "                    rise_vels.append(np.max(vel_seg))\n",
    "                else:\n",
    "                    fall_vels.append(np.min(vel_seg))\n",
    "\n",
    "    features.update(utils.get_descriptive_stats_short(np.array(rise_vels), 'velocity_pos'))\n",
    "    features.update(utils.get_descriptive_stats_short(np.array(fall_vels), 'velocity_neg'))\n",
    "\n",
    "    features['extraction_status'] = 'success'\n",
    "\n",
    "    if plot_results:\n",
    "        time_axis = np.linspace(0, len(detrended_signal) / FRAMERATE, len(detrended_signal))\n",
    "        visu.viz_irregular_events(time_axis=time_axis,\n",
    "                                  signal=detrended_signal,\n",
    "                                  features=features,\n",
    "                                  title='Adaptive 2-Pass Parameter Extraction')\n",
    "\n",
    "    return features\n",
    "\n",
    "\n",
    "def run_irregular_param_extraction(movement_paths_lst: list, landmark_lst: list, detection_dict: dict,\n",
    "                                   movement_func, framerate: float = FRAMERATE, plot_results: bool = False) -> list:\n",
    "    \"\"\"\n",
    "    Updates a movement feature file (.csv) with movement parameters extracted from a list of movement data files.\n",
    "\n",
    "    Args:\n",
    "        movement_paths_lst (list): list of movement file paths.\n",
    "        landmark_lst (list): list of landmark names.\n",
    "        detection_dict (dict): dictionary with parameters to tune the feature detection algorithm.\n",
    "        movement_func (function): function that extracts the basic movement from an exercise.\n",
    "        framerate (float): The framerate of the original video file.\n",
    "        plot_results (bool, optional): Whether to plot the extraction results. Defaults to False.\n",
    "\n",
    "    Returns:\n",
    "        feature_metrics_lst (list): list with dictionaries holding the extracted parameters of each exercise.\n",
    "    \"\"\"\n",
    "    # store a list with all feature for each movement file\n",
    "    feature_metrics_lst: list = []\n",
    "\n",
    "    # iterate over each participant\n",
    "    for movement_file in movement_paths_lst:\n",
    "\n",
    "        # load current movement file as DataFrame\n",
    "        movement_df: pd.DataFrame = pd.read_csv(movement_file)\n",
    "\n",
    "        # extract the landmarks of focus (varies by affected side and focused side)\n",
    "        new_landmark_lst = extract_landmarks_of_focus(movement_fpath=movement_file, landmark_lst=landmark_lst)\n",
    "\n",
    "        # get movement array (finger tapping amplitude, rotational angle, or similar)\n",
    "        movement_arr: np.ndarray = movement_func(movement_df, new_landmark_lst)\n",
    "\n",
    "        final_metrics = extract_irregular_movements_parameters(raw_signal=movement_arr, detection_config=detection_dict,\n",
    "                                                               framerate=framerate, plot_results=plot_results)\n",
    "\n",
    "        # add the current file path\n",
    "        final_metrics.update({'f_path': movement_file})\n",
    "\n",
    "        if final_metrics['extraction_status'] == 'success':\n",
    "            print(f'{os.path.basename(movement_file)}:')\n",
    "            for key in final_metrics.keys():\n",
    "                print(f'{key}: {final_metrics[key]}')\n",
    "        else:\n",
    "            print(f'Extraction of the current trial was unsuccessful: {os.path.basename(movement_file)}.')\n",
    "\n",
    "        feature_metrics_lst.append(final_metrics)\n",
    "\n",
    "    return feature_metrics_lst\n"
   ],
   "id": "530585834e0f1758",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 4.1) Pronation-Supination - Exercise 07/08",
   "id": "c9425c925b49273"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# 07: affected side; 08: healthy side\n",
    "exercise_num: str = '08'\n",
    "# wrist, index knuckle, and pinky knuckle\n",
    "landmark_lst = ['wrist', 'mcp2', 'mcp5']\n",
    "\n",
    "# feature detection dict\n",
    "sup_pro_dict: dict = {'min_segment_length': 0.05,\n",
    "                      'min_peak_amp_diff': 0.02,\n",
    "                      'min_peak_dur_diff': 0.10,\n",
    "                      'min_valley_amp_diff': 0.02,\n",
    "                      'min_valley_dur_diff': 0.06,\n",
    "                      'max_peak_amp_diff': 20.0,\n",
    "                      'max_peak_dur_diff': 5.0,\n",
    "                      'max_valley_amp_diff': 20.0}\n",
    "\n",
    "if exercise_num == '07':\n",
    "\n",
    "    current_trial_path_lst: list = hand_exercise_dict.get(exercise_num)\n",
    "\n",
    "    affected_suppro_feature_lst: list = run_irregular_param_extraction(movement_paths_lst=current_trial_path_lst,\n",
    "                                                                       landmark_lst=landmark_lst,\n",
    "                                                                       detection_dict=sup_pro_dict,\n",
    "                                                                       movement_func=motion_processing.calculate_3d_hand_rotation,\n",
    "                                                                       framerate=FRAMERATE,\n",
    "                                                                       plot_results=False)\n",
    "\n",
    "    utils.save_extracted_data_to_csv(affected_suppro_feature_lst, conf_dict=config, out_dir=param_extract_out_path, overwrite=False)\n",
    "\n",
    "elif exercise_num == '08':\n",
    "\n",
    "    current_trial_path_lst: list = hand_exercise_dict.get(exercise_num)\n",
    "\n",
    "    healthy_suppro_feature_lst: list = run_irregular_param_extraction(movement_paths_lst=current_trial_path_lst,\n",
    "                                                                      landmark_lst=landmark_lst,\n",
    "                                                                       detection_dict=sup_pro_dict,\n",
    "                                                                      movement_func=motion_processing.calculate_3d_hand_rotation,\n",
    "                                                                      framerate=FRAMERATE,\n",
    "                                                                      plot_results=False)\n",
    "\n",
    "    utils.save_extracted_data_to_csv(healthy_suppro_feature_lst, conf_dict=config, out_dir=param_extract_out_path, overwrite=False)\n"
   ],
   "id": "ccc1d6f39731fd7a",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
